{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CssVKVSJuxYY"
   },
   "source": [
    "\n",
    "# 270. 컴퓨터 비전(Vision)을 위한 전이학습(Transfer Learning)\n",
    "=======================================================\n",
    "\n",
    "- 실제로 충분한 크기의 데이터셋을 갖추기는 상대적으로 드물기 때문에, (무작위 초기화를 통해) 처음부터 합성곱 신경망(Convolutional Network) 전체를 작성하는 경우는 매우 적다.   \n",
    "\n",
    "\n",
    "- 대신, 매우 큰 데이터셋(예. 100가지 분류에 대해 120만개의 이미지가 포함된 ImageNet)에서 합성곱 신경망(ConvNet)을 미리 학습한 후, 이 합성곱 신경망을 관심있는 작업을 위한 초기 설정 또는 고정된 특징 추출기(fixed feature extractor)로 사용\n",
    "\n",
    "### 전이학습의 2 가지 시나리오:\n",
    "\n",
    "-  **합성곱 신경망의 미세조정(finetuning)**: 신경망을 ImageNet 등으로 미리 학습한 신경망으로 초기화하고 parameter 미세 조정  \n",
    "\n",
    "\n",
    "-  **고정된 특징 추출기로써의 합성곱 신경망**: 마지막 완전 연결층을 제외한 모든 신경망의 가중치를 고정. 마지막의 완전 연결층은 새로운 무작위의 가중치를 갖는 계층으로 대체되어 이 계층만 학습.  \n",
    "\n",
    "\n",
    "### torch 제공 pre-trained models\n",
    "```\n",
    "    import torchvision.models as models  \n",
    "    \n",
    "    resnet18 = models.resnet18()  \n",
    "    alexnet = models.alexnet()  \n",
    "    vgg16 = models.vgg16()  \n",
    "    squeezenet = models.squeezenet1_0()  \n",
    "    densenet = models.densenet161()  \n",
    "    inception = models.inception_v3()  \n",
    "    googlenet = models.googlenet()  \n",
    "    shufflenet = models.shufflenet_v2_x1_0()  \n",
    "    mobilenet = models.mobilenet_v2()  \n",
    "    resnext50_32x4d = models.resnext50_32x4d()  \n",
    "    wide_resnet50_2 = models.wide_resnet50_2()  \n",
    "    mnasnet = models.mnasnet1_0()  \n",
    "```   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gowJPapAuxYb"
   },
   "source": [
    "데이터 불러오기\n",
    "---------------\n",
    "\n",
    "- **개미** 와 **벌** 을 분류하는 이진 분류 모델을 학습\n",
    "    - 대략 120장 정도의 훈련 이미지와, 75장의 검증용 이미지를 이용\n",
    "    - 전이학습을 통해 소량의 데이터로도 일반화 가능\n",
    "    - ImageNet의 일부 data 이용\n",
    "\n",
    "-  데이터를 [여기](https://download.pytorch.org/tutorial/hymenoptera_data.zip)\n",
    "   에서 다운로드 받아 현재 디렉토리에 압축을 푼다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poKExvIiN9jE"
   },
   "source": [
    "- transforms.RandomResizedCrop(224):  랜덤으로 이미지를 자르고, 그 크기를 224x224로 조절  \n",
    "- transforms.RandomHorizontalFlip(): 이미지를 수평 방향으로 랜덤하게 뒤집기  \n",
    "- transforms.ToTensor(): PIL 이미지나 NumPy ndarray를 PyTorch의 텐서(Tensor)로 변환 및 픽셀 값을 [0., 1.] 범위로 조절.  \n",
    "- transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]): 텐서의 각 채널을 정규화합니다. 첫 번째 인자는 각 채널에 대한 평균, 두 번째 인자는 각 채널에 대한 표준편차. 이 숫자들은 ImageNet 데이터셋의 통계에서 파생된 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTHEd8-EuxYe"
   },
   "source": [
    "# ImageFolder 라이브러리\n",
    "\n",
    "- 계층적인 폴더 구조를 가지고 있는 데이터셋을 불러올 때 사용할 수 있다. 각 이미지들이 자신의 레이블(Label) 이름으로 된 폴더 안에 들어가 있는 구조라면, ImageFolder 라이브러리를 이용하여 이를 바로 불러와 객체로 만들면 된다.\n",
    "\n",
    "ImageFolder를 사용하기 위해선 가장 먼저 수집된 데이터의 폴더구조를 아래와 같이 설계해야한다  \n",
    "\n",
    "최상위 경로 아래에 각각의 class name을 가지는 폴더를 구성하고 그 하위경로에 이미지가 저장되어있는 방식이다.\n",
    "```\n",
    "root_dir\n",
    "    | --- ants/\n",
    "    |      |-- 0001.jpg\n",
    "    |      |-- 0002.jpg\n",
    "    |      |-- ...\n",
    "    | --- bees/\n",
    "    |      |-- 0001.jpg\n",
    "    |      |-- 0002.jpg\n",
    "    |      |-- ...\n",
    "    | --- rabbit/\n",
    "    |      |--...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DE9IcXkKuxYh"
   },
   "source": [
    "### `datasets.ImageFolder(folder, transform)` data loader 생성\n",
    "\n",
    "- torchvision.datasets.ImageFolder를 사용하여 지정된 경로에서 이미지 데이터셋을 로드하고, 로드된 이미지 데이터에 대해 특정 변환을 적용.  \n",
    "- os.path.join(data_dir, 'train')는 이미지 데이터셋이 저장된 폴더의 경로를 구성. 이 폴더 아래에는 각 클래스의 이름으로 된 폴더가 있으며, 각 클래스 폴더 안에는 해당 클래스의 이미지가 있다. 이 구조를 가진 폴더를 대상으로 ImageFolder를 사용하면, 각 폴더의 이름을 기반으로 클래스 레이블을 자동으로 생성.  \n",
    "- data_transforms['train']는 앞에서 정의한 변환(transform)을 이미지 데이터에 적용합니다. 이는 미리 정의한 data_transforms 딕셔너리에서 'train' 키를 가진 변환을 참조."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lDvPnhbuxYp"
   },
   "source": [
    "### 일부 이미지 시각화하기 \n",
    "\n",
    "- torchvision.utils.make_grid(tensor)\n",
    "    - tensor (Tensor or list) – (B x C x H x W)의 4D 미니 배치 텐서 또는 모두 같은 크기의 이미지 list 입니다.\n",
    "    - nrow (int, optional) – 그리드의 각 행에 표시되는 이미지 수입니다. 최종 그리드 크기는 (B / nrow, nrow)입니다. 기본값은 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMAmbZpTuxYr"
   },
   "source": [
    "Model Train\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_4mYKfeuxYt"
   },
   "source": [
    "## 방법 1. pre-trained  ResNet 신경망 전체를 미세조정(finetuning)\n",
    "\n",
    "- 미리 학습된 모델을 불러온 후 마지막의 완전 연결층 만을 새로 작성하고 **전체 parameter** 를 fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kONaHAoYUIyn"
   },
   "source": [
    "-  학습율(learning rate) 관리(scheduling)\n",
    "\n",
    "- 아래에서 ``scheduler`` 매개변수는 ``torch.optim.lr_scheduler`` 의 LR 스케쥴러 객체(Object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpE8EwiQuxY6"
   },
   "source": [
    "## 방법 2 : Pre-trained ResNet을 weight 고정된 특징 추출기로 사용\n",
    "\n",
    "- 미리 학습된 모델을 불러온 후 마지막의 **완전 연결층 만을 새로 작성**하되 마지막 계층을 제외한 **신경망의 모든 부분을 고정** (``requires_grad == False`` 로 설정)하여 ``backward()`` 중에 gradient가 계산되지 않도록 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SYcUB74uxY9"
   },
   "source": [
    "## Train & Evaluation"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
