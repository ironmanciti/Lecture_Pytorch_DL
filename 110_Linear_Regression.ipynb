{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 110. Basic Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1) torch.nn 의 Linear 클래스를 이용한 Linear Regression</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "torch.manual_seed(1)\n",
    "\n",
    "model = Linear(in_features=1, out_features=1, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>state_dict()</code> method 는 각 layer 의 parameter tensor 를 dictionary 로 반환하므로 직접 값을 update 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[0.5153]])), ('bias', tensor([-0.4414]))])\n",
      "\n",
      "tensor([[0.5153]]) tensor([-0.4414])\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[0.5153]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4414], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())\n",
    "print()\n",
    "print(model.state_dict()['weight'], model.state_dict()['bias'])\n",
    "print()\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "작동 원리 이해를 위해 weight와 bias 값을 임의로 assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()['weight'][0] = torch.tensor(2)\n",
    "model.state_dict()['bias'][0]     = torch.tensor(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([[2.]])), ('bias', tensor([-1.]))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network을 이용하여 $y = wx + b$ 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = [[3.0]]일 경우 prediction = 2*3 - 1 = 5\n",
    "x = torch.tensor([[3.0]])\n",
    "yhat = model(x)\n",
    "yhat.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [3.]\n",
      " [5.]]\n"
     ]
    }
   ],
   "source": [
    "# x 가 multiple inputs (array) 인 경우:\n",
    "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
    "yhat = model(x)\n",
    "print(yhat.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2) 사용자 정의 Neural Network 작성</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LR(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight', tensor([[-0.1939]])),\n",
       "             ('linear.bias', tensor([0.4694]))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LR(1, 1)\n",
    "\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에서와 마찬가지로 임의로 weight와 bias를 assign  \n",
    "- `model.parameters()` 함수는 PyTorch 모델의 모든 가중치와 편향(bias)을 포함하는 파라미터를 반환  \n",
    "    - requires_grad=True 는 해당 텐서에 대해 자동 미분을 수행하도록 설정합니다. 즉, 텐서에 대한 연산이 추적되며, 그래디언트 계산을 위한 연산 그래프가 구성됩니다. 이는 학습 가능한 모델 파라미터(가중치와 편향 등)에서 주로 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[2.]], requires_grad=True), Parameter containing:\n",
      "tensor([-1.], requires_grad=True)]\n",
      "\n",
      "Linear(in_features=1, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model.state_dict()['linear.weight'][0] = torch.tensor(2)\n",
    "model.state_dict()['linear.bias'][0]     = torch.tensor(-1)\n",
    "\n",
    "print(list(model.parameters()))\n",
    "print()\n",
    "print(model.linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [3.],\n",
       "        [5.]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
    "yhat = model(x)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [3.],\n",
       "       [5.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation 과 경사하강법 적용\n",
    "\n",
    "- weight 와 bias를 스스로 학습\n",
    "- (온도, 강수량, 습도)를 feature 로 입력 받아  (사과, 오렌지)의 수확량(label)을 선형회귀로 예측하는 model 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (습도, 강수량, 최고온도, 최저온도)\n",
    "inputs = np.array([\n",
    "                   [73, 67, 43, 10], \n",
    "                   [91, 88, 64, 5], \n",
    "                   [87, 134, 58, 2], \n",
    "                   [102, 43, 37, 4], \n",
    "                   [69, 96, 70, 5]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets - (apples, oranges) 수확량\n",
    "targets = np.array([\n",
    "                    [56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input 과 target을 tensor로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4])\n",
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs.size())\n",
    "print(targets.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) torch.nn Linear Class 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1df78b694b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "from torch import optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Linear(in_features=4, out_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    for x, y in zip(inputs, targets):\n",
    "        yhat = model(x)\n",
    "        loss = criterion(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0758, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "loss = criterion(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56.  70.]\n",
      " [ 81. 101.]\n",
      " [119. 133.]\n",
      " [ 22.  37.]\n",
      " [103. 119.]]\n",
      "\n",
      "[[ 58.021572  69.74707 ]\n",
      " [ 83.15649   98.7855  ]\n",
      " [119.965004 128.4409  ]\n",
      " [ 21.83963   34.988026]\n",
      " [102.8034   117.893616]]\n"
     ]
    }
   ],
   "source": [
    "# Predictions & target 비교\n",
    "print(targets.detach().numpy())\n",
    "print()\n",
    "print(preds.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) 사용자 정의 model 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Regression 사용자 정의 model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearReg(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        yhat = self.fc(x)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearReg(inputs.shape[1], targets.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearReg(\n",
      "  (fc): Linear(in_features=4, out_features=2, bias=True)\n",
      ")\n",
      "OrderedDict([('fc.weight', tensor([[ 0.1387,  0.0247,  0.1826, -0.1949],\n",
      "        [-0.0365, -0.0450,  0.0725, -0.0020]])), ('fc.bias', tensor([0.4371, 0.1556]))])\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {},\n",
       " 'param_groups': [{'lr': 0.0001,\n",
       "   'momentum': 0,\n",
       "   'dampening': 0,\n",
       "   'weight_decay': 0,\n",
       "   'nesterov': False,\n",
       "   'maximize': False,\n",
       "   'foreach': None,\n",
       "   'differentiable': False,\n",
       "   'params': [0, 1]}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    for x, y in zip(inputs, targets):\n",
    "        yhat = model(x)\n",
    "        loss = criterion(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.parameters(): 이 함수는 모델의 모든 파라미터를 생성자(generator) 형태로 반환합니다. 이는 주로 모델의 파라미터를 순회(iterate)하거나, 파라미터에 대한 그래디언트를 0으로 초기화하거나, 역전파를 위해 그래디언트를 사용하는 등의 작업에 사용됩니다.\n",
    "\n",
    "model.state_dict(): 이 함수는 모델의 상태를 Python 딕셔너리 형태로 반환합니다. 이 딕셔너리는 각 계층의 파라미터를 표현하는 텐서를 포함하며, 모델의 전체 상태를 표현합니다. 이 state_dict는 모델의 가중치를 저장하고 불러오는 데 사용되며, 모델의 학습 상태를 체크포인트로 저장하거나, 학습을 다시 시작할 때 이전 상태를 불러오는 등의 작업에 주로 사용됩니다.\n",
    "\n",
    "간단히 말해, model.parameters()는 모델의 파라미터를 바로 조작하는 데 사용되며, model.state_dict()는 모델의 상태를 저장하고 불러오는 데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.3590,  0.8959,  0.6336, -0.3657],\n",
       "         [-0.3081,  0.7807,  0.9301, -0.0332]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.4331, 0.1568], requires_grad=True)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc.weight',\n",
       "              tensor([[-0.3590,  0.8959,  0.6336, -0.3657],\n",
       "                      [-0.3081,  0.7807,  0.9301, -0.0332]])),\n",
       "             ('fc.bias', tensor([0.4331, 0.1568]))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56.  70.]\n",
      " [ 81. 101.]\n",
      " [119. 133.]\n",
      " [ 22.  37.]\n",
      " [103. 119.]]\n",
      "\n",
      "[[ 57.842937  69.6347  ]\n",
      " [ 85.32951  100.18176 ]\n",
      " [125.2741   131.84752 ]\n",
      " [ 24.323542  36.581146]\n",
      " [104.19539  118.78626 ]]\n"
     ]
    }
   ],
   "source": [
    "# Predictions & target 비교\n",
    "print(targets.detach().numpy())\n",
    "print()\n",
    "print(preds.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc.weight',\n",
       "              tensor([[-0.3590,  0.8959,  0.6336, -0.3657],\n",
       "                      [-0.3081,  0.7807,  0.9301, -0.0332]])),\n",
       "             ('fc.bias', tensor([0.4331, 0.1568]))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model save\n",
    "torch.save(model.state_dict(), 'model.pt')\n",
    "\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model reload 및 parameter 복원 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc.weight',\n",
       "              tensor([[-0.3590,  0.8959,  0.6336, -0.3657],\n",
       "                      [-0.3081,  0.7807,  0.9301, -0.0332]])),\n",
       "             ('fc.bias', tensor([0.4331, 0.1568]))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_model = LinearReg(inputs.shape[1], targets.shape[1])\n",
    "reloaded_model.load_state_dict(torch.load('model.pt'))\n",
    "\n",
    "reloaded_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = reloaded_model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56.  70.]\n",
      " [ 81. 101.]\n",
      " [119. 133.]\n",
      " [ 22.  37.]\n",
      " [103. 119.]]\n",
      "\n",
      "[[ 57.842937  69.6347  ]\n",
      " [ 85.32951  100.18176 ]\n",
      " [125.2741   131.84752 ]\n",
      " [ 24.323542  36.581146]\n",
      " [104.19539  118.78626 ]]\n"
     ]
    }
   ],
   "source": [
    "# Predictions & target 비교\n",
    "print(targets.detach().numpy())\n",
    "print()\n",
    "print(preds.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
